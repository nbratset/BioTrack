{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe4c181",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install necessary libraries\n",
    "pip install rpy2 pandas numpy matplotlib seaborn scipy statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92bb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from microbiomeutil import MicrobiomeDataset\n",
    "from skbio.diversity import beta_diversity\n",
    "from skbio.diversity import tree as skbio_tree\n",
    "from skbio.stats.ordination import pcoa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skbio import TreeNode\n",
    "import pingouin as pg\n",
    "from skbio.diversity.alpha import shannon, simpson, observed_otus\n",
    "from statsmodels.robust.robust_linear_model import RLM\n",
    "from microbiomeutil import MicrobiomeDataset\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "from ete3 import Tree\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy.stats import zscore\n",
    "from pathlib import Path\n",
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "ro.r('library(Maaslin2)')\n",
    "ro.r('library(dplyr)')\n",
    "ro.r('library(tibble)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6ce613",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a phyloseq object: a phyloseq object is a data structure that contains the taxonomy information (taxa_table), \n",
    "#abundances of respective taxonomy in each sample (otu_table), and a sample metadata. Our taxa_table and otu_table are\n",
    "#parsed from the final output of our Nextflow pipeline. The Nextflow pipeline uses Metaphlan to characterize \n",
    "# taxonomy and calculate their abundances in each sample.\n",
    "\n",
    "# Read MetaPhlAn output\n",
    "metaphlan = pd.read_csv(\"metaphlan_output.tsv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "# Split the taxonomy string into columns\n",
    "taxonomy = metaphlan.index.to_series().str.split(\"|\", expand=True)\n",
    "taxonomy.columns = [\"Kingdom\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\", \"Species\"][:taxonomy.shape[1]]\n",
    "\n",
    "# Clean names\n",
    "taxonomy = taxonomy.replace(\"\", pd.NA)\n",
    "taxonomy = taxonomy.fillna(\"Unclassified\")\n",
    "\n",
    "# Create OTU (feature) table\n",
    "otu_table = metaphlan.copy()\n",
    "otu_table.index = [f\"OTU_{i}\" for i in range(len(otu_table))]\n",
    "\n",
    "# Match taxonomy rows to OTUs\n",
    "taxonomy.index = otu_table.index\n",
    "\n",
    "#Read metadata \n",
    "metadata = pd.read_csv(\"sample_metadata.tsv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "#Build a tree\n",
    "tree = Tree()\n",
    "nodes = {}\n",
    "\n",
    "for otu, row in taxonomy.iterrows():\n",
    "    lineage = [t for t in row if t != \"Unclassified\"]\n",
    "    parent = tree\n",
    "    for rank in lineage:\n",
    "        if rank not in nodes:\n",
    "            nodes[rank] = parent.add_child(name=rank)\n",
    "        parent = nodes[rank]\n",
    "    parent.add_child(name=otu)\n",
    "\n",
    "#Check whether taxa and samples align between the 3 dataframes\n",
    "otu_table = otu_table.loc[taxonomy.index.intersection(otu_table.index)]  # align taxa\n",
    "metadata = metadata.loc[otu_table.columns.intersection(metadata.index)]  # align samples\n",
    "\n",
    "# Create the MicrobiomeDataset object (phyloseq)\n",
    "ps = MicrobiomeDataset(\n",
    "    feature_table=otu_table,\n",
    "    taxonomy=taxonomy,\n",
    "    sample_metadata=metadata,\n",
    "    tree=tree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56382ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#QC: We need to perform quality control to filter out \"noisy\" signals\n",
    "\n",
    "#Remove low abundance, low prevalence taxa\n",
    "keep_taxa = (otu_table.sum(axis=1)) > 5 #Remove taxa that are present in less than 5 samples\n",
    "otu_table_filt = otu_table.loc[keep_taxa]\n",
    "\n",
    "#Remove lowly covered samples\n",
    "keep_samples = otu_table_filt.sum(axis=0) > 5000 #Remove samples with less than 5000 reads\n",
    "otu_table_filt = otu_table_filt.loc[:, keep_samples]\n",
    "metadata = metadata.loc[keep_samples]\n",
    "\n",
    "#Remove unwanted taxa\n",
    "mask = (\n",
    "    (taxonomy[\"Kingdom\"] != \"Eukaryota\") &\n",
    "    ((taxonomy[\"Order\"].isna()) | (taxonomy[\"Order\"] != \"Chloroplast\"))) #Remove non-bacterial reads\n",
    "\n",
    "taxonomy_filt = taxonomy.loc[mask]\n",
    "\n",
    "# Ensure consistency with filtered OTU table\n",
    "otu_table_filt = otu_table_filt.loc[otu_table_filt.index.intersection(taxonomy_filt.index)]\n",
    "\n",
    "# Rebuild MicrobiomeDataset \n",
    "ps_filtered = MicrobiomeDataset(\n",
    "    feature_table=otu_table_filt,\n",
    "    taxonomy=taxonomy_filt,\n",
    "    sample_metadata=metadata,\n",
    "    tree=tree\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b3ad01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Principal Coordinate Analysis \n",
    "\n",
    "def calc_unifrac(ps_filtered):\n",
    "    # Calculate weighted Unufrac distances\n",
    "    otu_table = ps_filtered.feature_table.T  \n",
    "    tree = ps_filtered.tree  \n",
    "    sample_ids = otu_table.index\n",
    "\n",
    "    # Calculate UniFrac\n",
    "    unifrac_dm = beta_diversity(\n",
    "        metric='weighted_unifrac',\n",
    "        counts=otu_table.values,\n",
    "        ids=sample_ids,\n",
    "        tree=tree\n",
    "    )\n",
    "    return unifrac_dm, otu_table, sample_ids\n",
    "\n",
    "def pcoa(unifrac_dm, ps_filtered):\n",
    "    # Perform PCoA \n",
    "    pcoa_res = pcoa(unifrac_dm)\n",
    "\n",
    "    # Eigenvalues and explained variance\n",
    "    evals = pcoa_res.eigvals\n",
    "    explained = evals / evals.sum()\n",
    "\n",
    "    print(\"Explained variance (first 6 axes):\", explained.head(6))\n",
    "\n",
    "    #Add PCoA axes to metadata\n",
    "    pcoa_df = pcoa_res.samples.copy()\n",
    "    pcoa_df.columns = [f\"PCoA{i+1}\" for i in range(pcoa_df.shape[1])]\n",
    "    sampledf = ps_filtered.sample_metadata.join(pcoa_df)\n",
    "\n",
    "    return sampledf, explained\n",
    "\n",
    "def scree_plot(explained, save=False):\n",
    "    # Scree plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.barplot(x=np.arange(1, 21), y=explained.values[:20])\n",
    "    plt.xlabel(\"PCoA Axis\")\n",
    "    plt.ylabel(\"Variance Explained\")\n",
    "    plt.title(\"Weighted UniFrac PCoA Scree Plot\")\n",
    "    if save:\n",
    "        plt.savefig('Scree_plot.png', dpi=600)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def ordination_scatter_plot(sampledf, explained, save=False):\n",
    "    # Ordination scatter plot\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.scatterplot(\n",
    "        data=sampledf,\n",
    "        x='PCoA1', y='PCoA2',\n",
    "        hue='Lifestyle',\n",
    "        style='Sex',\n",
    "        alpha=0.9,\n",
    "        s=80\n",
    "    )\n",
    "    plt.axhline(0, color='gray', linestyle='--', lw=0.8)\n",
    "    plt.axvline(0, color='gray', linestyle='--', lw=0.8)\n",
    "    plt.title(f\"Weighted UniFrac PCoA\\n(PCo1: {explained.iloc[0]*100:.1f}%, PCo2: {explained.iloc[1]*100:.1f}%)\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('Ordination_scatter_plot.png', dpi=600)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def permanova(unifrac_dm, sampledf):\n",
    "    #PERMANOVA\n",
    "    dist_matrix = pd.DataFrame(\n",
    "        unifrac_dm.data, \n",
    "        index=unifrac_dm.ids, \n",
    "        columns=unifrac_dm.ids\n",
    "    )\n",
    "\n",
    "    sampledf = sampledf.loc[dist_matrix.index]\n",
    "\n",
    "    permanova_results = pg.permanova(\n",
    "        distance=dist_matrix,\n",
    "        metadata=sampledf[['Lifestyle', 'Latitude', 'Longtitude', 'Altitude', 'Age.C', 'Sex', 'Shelter']],\n",
    "        n_perm=9999\n",
    "    )\n",
    "\n",
    "    print(permanova_results)\n",
    "\n",
    "unifrac_dm, otu_table, sample_ids = calc_unifrac(ps_filtered)\n",
    "sampledf, explained = pcoa(unifrac_dm, ps_filtered)\n",
    "scree_plot(explained, save=False)\n",
    "ordination_scatter_plot(sampledf, explained, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23203fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alpha diversity\n",
    "\n",
    "def plot_shannon_div(alpha_df, save=False):\n",
    "    # Visualize Shannon diversity \n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(\n",
    "        data=alpha_df,\n",
    "        x=\"Lifestyle\", y=\"Shannon\",\n",
    "        palette=\"viridis\", fliersize=3\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=alpha_df,\n",
    "        x=\"Lifestyle\", y=\"Shannon\",\n",
    "        color=\"black\", size=3, alpha=0.5\n",
    "    )\n",
    "    plt.title(\"Shannon Diversity by Lifestyle\")\n",
    "    plt.ylabel(\"Shannon Index (bits)\")\n",
    "    plt.xlabel(\"Lifestyle\")\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('Shannon_diversity.png', dpi=600)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def plot_richness(alpha_df, save=False):\n",
    "    # Visualize richness similarly \n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(\n",
    "        data=alpha_df,\n",
    "        x=\"Lifestyle\", y=\"Richness\",\n",
    "        palette=\"magma\", fliersize=3\n",
    "    )\n",
    "    sns.stripplot(\n",
    "        data=alpha_df,\n",
    "        x=\"Lifestyle\", y=\"Richness\",\n",
    "        color=\"black\", size=3, alpha=0.5\n",
    "    )\n",
    "    plt.title(\"Observed Species Richness by Lifestyle\")\n",
    "    plt.ylabel(\"Number of Taxa Observed\")\n",
    "    plt.xlabel(\"Lifestyle\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig('Richness_similarity.png', dpi=600)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def calc_alpha_div(otu_table, metadata):\n",
    "    # Compute alpha diversity metrics \n",
    "    alpha_div = pd.DataFrame(index=otu_table.index)\n",
    "    alpha_div[\"Shannon\"] = otu_table.apply(lambda x: shannon(x.values, base=2), axis=1)\n",
    "    alpha_div[\"Simpson\"] = otu_table.apply(lambda x: simpson(x.values), axis=1)\n",
    "    alpha_div[\"Richness\"] = otu_table.apply(lambda x: (x > 0).sum(), axis=1)\n",
    "\n",
    "    # Combine with metadata\n",
    "    alpha_df = metadata.join(alpha_div)\n",
    "\n",
    "    # Export for downstream stats\n",
    "    alpha_df.to_csv(\"alpha_diversity_metrics.tsv\", sep=\"\\t\")\n",
    "\n",
    "    #Statistical Tests\n",
    "    pg.kruskal(data=alpha_df, dv='Shannon', between='Lifestyle')\n",
    "\n",
    "    model_rlm = smf.rlm(\n",
    "        formula='Shannon ~ C(Lifestyle) + Age.C + Altitude + Latitude + C(Sex)',\n",
    "        data=alpha_df\n",
    "    ).fit()\n",
    "\n",
    "    print(model_rlm.summary())\n",
    "    return alpha_df\n",
    "\n",
    "alpha_df = calc_alpha_div(otu_table, metadata)\n",
    "plot_shannon_div(alpha_df, save=False)\n",
    "plot_richness(alpha_df, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91651472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the top most taxa\n",
    "def calc_taxa(otu_table, metadata):\n",
    "    mean_abundance = otu_table.mean(axis=1)\n",
    "    top20_taxa = mean_abundance.sort_values(ascending=False).head(20).index\n",
    "    otu_top20 = otu_table.loc[top20_taxa]\n",
    "\n",
    "    otu_long = (\n",
    "        otu_top20\n",
    "        .T\n",
    "        .reset_index()\n",
    "        .melt(id_vars='index', var_name='Taxon', value_name='Abundance')\n",
    "        .rename(columns={'index': 'SampleID'})\n",
    "    )\n",
    "\n",
    "    otu_long = otu_long.merge(metadata, left_on='SampleID', right_index=True)\n",
    "\n",
    "    otu_long_grouped = (\n",
    "        otu_long\n",
    "        .groupby(['Lifestyle','Taxon'])['Abundance']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    return otu_long_grouped\n",
    "\n",
    "def plot_taxa(otu_long_grouped, save=False):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(\n",
    "        data=otu_long_grouped,\n",
    "        x='Lifestyle',\n",
    "        y='Abundance',\n",
    "        hue='Taxon'\n",
    "    )\n",
    "\n",
    "    plt.ylabel(\"Mean Relative Abundance\")\n",
    "    plt.title(\"Top 20 Taxa by Lifestyle\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    if save:\n",
    "        plt.savefig('Taxa_plot.png', dpi=600)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "otu_long_grouped = calc_taxa(otu_table, metadata)\n",
    "plot_taxa(otu_long_grouped, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68387ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "# Combine metadata + OTU table\n",
    "data = otu_table.copy()\n",
    "data[\"Lifestyle\"] = metadata[\"Lifestyle\"]\n",
    "\n",
    "# Train-test split (80/20) \n",
    "X = data.drop(columns=\"Lifestyle\")\n",
    "y = data[\"Lifestyle\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=100\n",
    ")\n",
    "\n",
    "# Random Forest with repeated CV \n",
    "rf = RandomForestClassifier(random_state=100)\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=100)\n",
    "\n",
    "param_grid = {\"n_estimators\": [100, 300, 500], \"max_features\": [\"sqrt\", \"log2\", None]}\n",
    "grid = GridSearchCV(\n",
    "    rf, param_grid, cv=cv, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "rf_best = grid.best_estimator_\n",
    "print(\"Best RF model:\", grid.best_params_)\n",
    "\n",
    "# Evaluate on test set \n",
    "y_pred = rf_best.predict(X_test)\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "#  ROC Curves (multiclass) \n",
    "y_test_bin = label_binarize(y_test, classes=rf_best.classes_)\n",
    "y_score = rf_best.predict_proba(X_test)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "colors = [\"#F60239\",\"#008607\",\"#00DBC5\",\"#003C86\",\"#9400E6\"]\n",
    "\n",
    "for i, cls in enumerate(rf_best.classes_):\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin[:, i], y_score[:, i])\n",
    "    auc = roc_auc_score(y_test_bin[:, i], y_score[:, i])\n",
    "    plt.plot(fpr, tpr, color=colors[i], label=f\"{cls} (AUC={auc:.2f})\")\n",
    "\n",
    "plt.plot([0,1],[0,1],\"k--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(title=\"Lifestyle\", bbox_to_anchor=(1.05, 1))\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"AUC_Lifestyle.pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Variable Importance Factors\n",
    "importances = pd.DataFrame({\n",
    "    \"ASV\": X.columns,\n",
    "    \"Importance\": rf_best.feature_importances_\n",
    "}).sort_values(\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(5,6))\n",
    "sns.stripplot(data=importances.head(30), x=\"Importance\", y=\"ASV\", size=4)\n",
    "plt.axvline(x=0.01, color=\"red\", linestyle=\"--\")\n",
    "plt.title(\"Top Variable Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Filter features with importance > threshold\n",
    "imp_features = importances.query(\"Importance > 0.01\")[\"ASV\"]\n",
    "print(\"Top features:\", imp_features.head())\n",
    "\n",
    "# Construct taxonomic annotation table\n",
    "tax_df = taxonomy.copy()\n",
    "tax_df[\"TaxaName\"] = tax_df.fillna(\"__\").apply(lambda x: \"-\".join(x.astype(str)), axis=1)\n",
    "tax_df[\"ASV\"] = tax_df.index\n",
    "tax_df = tax_df.reset_index(drop=True)\n",
    "print(tax_df.head())\n",
    "\n",
    "# Heatmap of important taxa \n",
    "otu_rel = otu.div(otu_table.sum(axis=1), axis=0)\n",
    "otu_imp = otu_rel[imp_features]\n",
    "otu_melt = otu_imp.melt(ignore_index=False, var_name=\"OTU\", value_name=\"Abundance\")\n",
    "otu_melt = otu_melt.merge(metadata, left_index=True, right_index=True)\n",
    "\n",
    "# Mean abundance by Lifestyle\n",
    "otu_mean = (\n",
    "    otu_melt.groupby([\"Lifestyle\", \"OTU\"])[\"Abundance\"]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .pivot(index=\"OTU\", columns=\"Lifestyle\", values=\"Abundance\")\n",
    ")\n",
    "\n",
    "# z-score normalization\n",
    "otu_z = otu_mean.apply(zscore, axis=1)\n",
    "\n",
    "sns.clustermap(\n",
    "    otu_z,\n",
    "    cmap=\"YlOrRd\",\n",
    "    figsize=(8,6),\n",
    "    row_cluster=True,\n",
    "    col_cluster=False\n",
    ")\n",
    "plt.title(\"Top Variable Taxa (z-score normalized)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f881a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Maaslin\n",
    "\n",
    "def maaslin(otu_table, metadata):\n",
    "  df_input_data = otu_table.T.copy()   \n",
    "  df_input_metadata = metadata.copy()\n",
    "\n",
    "  # Maaslin wants numeric features (no NA feature names)\n",
    "  # add 1 pseudocount as in your R code\n",
    "  df_input_data = df_input_data.apply(pd.to_numeric, errors='coerce').fillna(0) + 1\n",
    "\n",
    "  # Write temporary CSVs (MaAsLin2 reads files)\n",
    "  outdir = \"maaslin2_output\"\n",
    "  Path(outdir).mkdir(exist_ok=True)\n",
    "\n",
    "  data_csv = Path(outdir) / \"maaslin_input.tsv\"\n",
    "  meta_csv = Path(outdir) / \"maaslin_meta.tsv\"\n",
    "  df_input_data.to_csv(data_csv, sep=\"\\t\", index=True)\n",
    "  df_input_metadata.to_csv(meta_csv, sep=\"\\t\", index=True)\n",
    "\n",
    "  # Prepare R call \n",
    "  r_data = str(data_csv)\n",
    "  r_meta = str(meta_csv)\n",
    "  r_out = str(Path(outdir) / \"maaslin_res\")\n",
    "\n",
    "  # Example: fixed_effects = c(\"Lifestyle\"), reference = c(\"Lifestyle,1.Foragers\")\n",
    "  r_cmd = f'''\n",
    "  fit_data2 <- Maaslin2(\n",
    "    input_data = \"{r_data}\",\n",
    "    input_metadata = \"{r_meta}\",\n",
    "    min_prevalence = 0,\n",
    "    analysis_method = \"NEGBIN\",\n",
    "    normalization = \"CSS\",\n",
    "    transform = 'NONE',\n",
    "    output = \"{r_out}\",\n",
    "    fixed_effects = c(\"Lifestyle\"),\n",
    "    reference = c(\"Lifestyle,1.Foragers\")\n",
    "  )\n",
    "  '''\n",
    "  ro.r(r_cmd)\n",
    "\n",
    "  return r_out, df_input_metadata\n",
    "\n",
    "def tax_join(r_out, tax_df):\n",
    "  # After MaAsLin2 completes, read the all_results.tsv produced by it\n",
    "  res_file = Path(r_out) / \"all_results.tsv\"\n",
    "  df_res = pd.read_csv(res_file, sep=\"\\t\")\n",
    "  df_res['feature'] = df_res['feature'].astype(str).str.replace('-', '.', regex=False).str.replace('_', '.', regex=False)\n",
    "\n",
    "  # Join taxonomy in Python (make sure tax_df feature names match)\n",
    "  tax_join = tax_df.copy()\n",
    "  tax_join = tax_join.replace({np.nan: \"__\"})\n",
    "  tax_join['best_hit'] = tax_join['best_hit'].astype(str).str.replace('_', '.', regex=False).str.replace(':', '.', regex=False).str.replace('-', '.', regex=False)\n",
    "  tax_join['feature'] = tax_join['best_hit']\n",
    "\n",
    "  df_res = df_res.merge(tax_join.reset_index(), how='left', on='feature')\n",
    "\n",
    "  # Filter hits (example -log10(qval) > 40)\n",
    "  df_res['neglog10q'] = -np.log10(df_res['qval'] + 1e-300)\n",
    "  df_subset = df_res[df_res['neglog10q'] > 40]\n",
    "  return df_res, df_subset\n",
    "\n",
    "def volcano_plot(df_res):\n",
    "  # Plot volcano-like plot (coef vs -log10 qval)\n",
    "  plt.figure(figsize=(6,4))\n",
    "  palette = dict(zip(df_res['Phylum'].unique(), sns.color_palette(\"tab10\", n_colors=df_res['Phylum'].nunique())))\n",
    "  sns.scatterplot(data=df_res, x='coef', y='neglog10q', hue='Phylum', palette=palette, s=40)\n",
    "  plt.axhline(-np.log10(0.05), linestyle='--', color='red')\n",
    "  plt.axvline(-1, linestyle='--', color='red')\n",
    "  plt.axvline(1, linestyle='--', color='red')\n",
    "  plt.title(\"MaAsLin2: coefficient vs -log10(qval)\")\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(\"Maaslin_lifestyle_volcano.png\", dpi=300)\n",
    "  plt.show()\n",
    "\n",
    "def plot_abundance_per_lifestyle(df_res, otu_table, df_input_metadata):\n",
    "  # Identify significant features (qval < 0.05 & abs(coef)>1)\n",
    "  df_sig = df_res[(df_res['qval'] < 0.05) & (df_res['coef'].abs() > 1)]\n",
    "  sig_features = df_sig['feature'].unique().tolist()\n",
    "\n",
    "  # Make heatmap: take mean abundance per Lifestyle for sig features\n",
    "  # Ensure otu_df columns match feature naming used by MaAsLin (transform if needed)\n",
    "  # Reformat OTU names similar to R (replace :, -, _ with .) if necessary\n",
    "  otu_for_merge = otu_table.copy()\n",
    "  otu_for_merge.index = otu_for_merge.index.astype(str).str.replace(':', '.', regex=False).str.replace('-', '.', regex=False).str.replace('_', '.', regex=False)\n",
    "\n",
    "  # Subset and compute mean abundance per Lifestyle\n",
    "  otu_sig = otu_for_merge.loc[otu_for_merge.index.intersection(sig_features)]\n",
    "  if otu_sig.shape[0] == 0:\n",
    "      print(\"No significant features found to plot heatmap.\")\n",
    "  else:\n",
    "      otu_sig_T = otu_sig.T\n",
    "      merged = otu_sig_T.merge(df_input_metadata[['Lifestyle']], left_index=True, right_index=True)\n",
    "      mean_by_group = merged.groupby('Lifestyle').mean().T  # features x Lifestyle\n",
    "\n",
    "      # X- score normalize rows (features)\n",
    "      mean_by_group_z = mean_by_group.apply(zscore, axis=1).fillna(0)\n",
    "\n",
    "      sns.clustermap(mean_by_group_z, cmap=\"YlOrRd\", col_cluster=False, figsize=(8, max(4, 0.2*mean_by_group_z.shape[0])))\n",
    "      plt.suptitle(\"MaAsLin2 significant features (z-scored means by Lifestyle)\")\n",
    "      plt.savefig(\"Maaslin_heatmap.png\", dpi=300)\n",
    "      plt.show()\n",
    "\n",
    "r_out, df_input_metadata = maaslin(otu_table, metadata)\n",
    "df_res, df_subset = tax_join(r_out, tax_df)\n",
    "volcano_plot(df_res)\n",
    "plot_abundance_per_lifestyle(df_res, otu_table, df_input_metadata)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
